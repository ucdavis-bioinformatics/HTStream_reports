---
title: "Preproc mapping stats for Dickinson - Choroid Plexus"
output: html_notebook
---

```{r, echo=FALSE}
### SETTINGS ###
# full path to working directory
working_dir = "/share/biocore/joshi/projects/Dickinson_P_UCDVM/2019_choroid_plexus"
# pre-processing directory name
preproc_dir = "01-Cleaned"
# suffix for pre-processing Log files
preproc_suffix=".stats.log"
# mapping directory name
mapping_dir = "02-STAR"
# delimiter between sample name and suffix for mapping files
mapping_file_delimiter="."
# sample file name in working dir. If left empty,
# sample names will be found from directory names in preproc_dir.
samples_file=""
######################
```

```{r setup, echo=FALSE}
knitr::opts_knit$set(root.dir = working_dir)
```

```{r, echo=FALSE, message=FALSE}
library(knitr)
library(kableExtra)
library(jsonlite)
library(readr)
library(stringr)
library(edgeR)
library(ggplot2)
library(dplyr)
library(gridExtra)

process_step <- function(json_step,step_name,orig_input) {
    if (startsWith(step_name,"hts_Stats")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("Stats Input"=json_step$totalFragmentsInput, "Stats Output"=json_step$totalFragmentsOutput, "Stats Perc"=perc)
    } else if (startsWith(step_name,"hts_SeqScreener")) {
        if (json_step$record == 1) {
            total_hits = json_step$Single_end$SE_hits + json_step$Paired_end$PE_hits
            perc = sprintf("%.02f%%",100*total_hits/orig_input)
            retval = c("SeqScreener Reads"=json_step$totalFragmentsInput, "SeqScreener Recorded Contaminants"=total_hits, "Perc Recorded Contaminants"=perc)
        } else {
            perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
            retval = c("SeqScreener Input"=json_step$totalFragmentsInput, "SeqScreener Output"=json_step$totalFragmentsOutput, "SeqScreener Perc"=perc)
        }
    } else if (startsWith(step_name,"hts_SuperDeduper")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("SuperDeduper Input"=json_step$totalFragmentsInput, "SuperDeduper Output"=json_step$totalFragmentsOutput, "SuperDeduper Perc"=perc)
    } else if (startsWith(step_name,"hts_AdapterTrimmer")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("AdapterTrimmer Input"=json_step$totalFragmentsInput, "AdapterTrimmer Output"=json_step$totalFragmentsOutput, "AdapterTrimmer Perc"=perc)
    } else if (startsWith(step_name,"hts_QWindowTrim")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("QWindowTrim Input"=json_step$totalFragmentsInput, "QWindowTrim Output"=json_step$totalFragmentsOutput, "QWindowTrim Perc"=perc)
    } else if (startsWith(step_name,"hts_CutTrim")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("CutTrim Input"=json_step$totalFragmentsInput, "CutTrim Output"=json_step$totalFragmentsOutput, "CutTrim Perc"=perc)
    } else if (startsWith(step_name,"hts_Overlapper")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("Overlapper Input"=json_step$totalFragmentsInput, "Overlapper Output"=json_step$totalFragmentsOutput, "Overlapper Perc"=perc)
    } else if (startsWith(step_name,"hts_NTrimmer")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("NTrimmer Input"=json_step$totalFragmentsInput, "NTrimmer Output"=json_step$totalFragmentsOutput, "NTrimmer Perc"=perc)
    } else if (startsWith(step_name,"hts_PolyATTrim")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("PolyATTrim Input"=json_step$totalFragmentsInput, "PolyATTrim Output"=json_step$totalFragmentsOutput, "PolyATTrim Perc"=perc)
    }
  
    return(retval)
}

process_json <- function(sdir) { 
    json <- fromJSON(paste0(preproc_dir,"/",sdir,"/",sdir,preproc_suffix))
    
    first_step = names(json)[1]
    orig_input = json[[first_step]]$totalFragmentsInput
    
    stats = unlist(lapply(names(json), function(x)
      process_step(json[[x]],x,orig_input)))
    
    logfinal = read_file(paste0(mapping_dir,"/",sdir,"/",sdir,mapping_file_delimiter,"Log.final.out"))
    lfall = str_match_all(logfinal,"(?s)Uniquely mapped reads number \\|\\t(\\d+)\\n.+Uniquely mapped reads \\% \\|\\t(.+?\\%).+Number of reads mapped to multiple loci \\|\\t(\\d+)\\n.+\\% of reads mapped to multiple loci \\|\\t(.+?\\%)")
    
    lfm = c("Uniquely Mapped Reads"=lfall[[1]][,2], "Perc Uniquely Mapped"=lfall[[1]][,3], "Multi-Mapped Reads"=lfall[[1]][,4], "Perc Multi-Mapped"=lfall[[1]][,5])
    
    stats = c(stats,lfm)
    return(stats)
}

process_counts <- function(sid, colnum) {
  counts = read.table(paste0(mapping_dir,"/",sid,"/",sid,mapping_file_delimiter,"ReadsPerGene.out.tab"),row.names = 1,skip = 4,sep='\t',stringsAsFactors = F)
  counts = counts[,colnum]
  return(counts)
}
```

```{r, echo=FALSE}
###################
if (samples_file == "") {
    sample_dirs = list.dirs(preproc_dir,full.names = F, recursive = F)
} else {
    sf = read.table(samples_file,header = F,stringsAsFactors = F)
    sample_dirs = sf[,1]
}
final_stats = t(sapply(sample_dirs, process_json))

#remove stats columns
stats_cols = which(startsWith(colnames(final_stats),"Stats"))
final_stats = final_stats[,-stats_cols]

# figure out which column to use
counts = read.table(paste0(mapping_dir,"/",sample_dirs[1],"/",sample_dirs[1],mapping_file_delimiter,"ReadsPerGene.out.tab"),row.names = 1,skip = 4,sep='\t',stringsAsFactors = F)
ccs <- colSums(counts)
if (ccs[1]/ccs[3] > 5 || ccs[1]/ccs[2] > 5) {
    ## appears to be stranded, so pick the one with the most reads
    strandcol = which.max(ccs[2:3])+1
} else { ## appears to be not stranded, choose column 1 (both)
    strandcol = 1
}

counts_all = sapply(sample_dirs,process_counts,colnum=strandcol)
rownames(counts_all) = rownames(counts)

write.table(counts_all,file="counts_all.out",sep='\t',quote=F,row.names=T)

rmg = as.matrix(colSums(counts_all), ncol=1)
mr = as.matrix(as.integer(final_stats[,1]), ncol=1)
perc_rmg = as.matrix(sprintf("%.02f%%", (rmg / mr) * 100), ncol=1)

fscol = colnames(final_stats)
final_stats = cbind(final_stats,rmg,perc_rmg)
colnames(final_stats) = c(fscol,"Reads Mapped to Genes","Perc Reads Mapped to Genes")

###################
```

## <u>**Preprocessing & Mapping stats**</u>
Preprocessing was done using the [HTStream](https://ibest.github.io/HTStream/) software. The table below shows the number of reads input and output at each step as well as the percentage of reads left (based on the initial input amount). Here are explantions of the various possible steps in your output (Note, your output will not contain every one of these steps):

* hts_AdapterTrimmer: Trims adapters which are sequenced when the fragment insert length is shorter than the read length.
* hts_CutTrim: Trims a fixed number of bases from the 5' and/or 3' end of each read.
* hts_Overlapper: Overlaps paired end reads to produce the original fragment, trims adapters, and can correct sequencing errors.
* hts_QWindowTrim: Uses a sliding window approach to remove the low quality ends of reads.
* hts_Stats: Generates an JSON formatted file containing a set of statistical measures about the input read data.
* hts_NTrimmer: Trims reads to the longest subsequence that contains no Ns.
* hts_PolyATTrim: Trims poly-A and poly-T sequences from the end of reads.
* hts_SeqScreener: A simple sequence screening tool which uses a kmer lookup approach to identify reads from an unwanted source. By default it will look for reads which are likely to have come from PhiX (commonly added to Illumina sequencing runs).
* hts_SuperDeduper: A reference free duplicate read removal tool.

The "Uniquely Mapped Reads", "Uniquely Mapped Perc", "Multi-Mapped Reads", and "Multi-Mapped Perc" columns are all taken from the log files of the aligner. Finally, the "Reads Mapped to Genes", and "Perc Reads Mapped to Genes" columns are calculated from the files of count data and original input numbers.

```{r, echo=FALSE}
numcol = dim(final_stats)[2]
step=6
for (i in seq(1,numcol,step)) {
  if (i+step-1 <= numcol) {
    endcol <- i+step-1
  } else {
    endcol <- numcol
  }
  
  print(kable(final_stats[,i:endcol]) %>% kable_styling(bootstrap_options = c("striped", "hover")))
}
```


```{r, echo=FALSE, fig.height=10, fig.width=10}
calc_diffs <- function(input_nums,output_nums) {
    rn_len = dim(input_nums)[1]
    numsteps = dim(input_nums)[2]
    
    retval=c()
    for (i in 1:numsteps) {
        retval = append(retval,as.numeric(input_nums[,i]-output_nums[,i]))
    }
    
    retval = append(retval,as.numeric(output_nums[,numsteps]))
    return(retval)
}

input_colnums = which(endsWith(colnames(final_stats),"Input"))
output_colnums = which(endsWith(colnames(final_stats),"Output"))
input_nums = final_stats[,input_colnums]
output_nums = final_stats[,output_colnums]
mode(input_nums) <- "numeric"
mode(output_nums) <- "numeric"

rn = rownames(input_nums)
rn_len = length(rn)
numsteps = dim(input_nums)[2]
samps = rep(rn,numsteps+1)
columns = unlist(lapply(1:(numsteps+1), function(x) rep(x,rn_len)))
diffs = calc_diffs(input_nums,output_nums)

data=data.frame(samps,columns=factor(columns),diffs)
labels = c(gsub(" Input","",colnames(final_stats)[input_colnums]), "Reads Remaining")

if ("SeqScreener Recorded Contaminants" %in% colnames(final_stats)) {
    contam = as.numeric(final_stats[,"SeqScreener Recorded Contaminants"])
    dffs1 = data.frame(x=rownames(final_stats),y=contam/as.numeric(final_stats[,1]))
    dffs2 = data.frame(x=rownames(final_stats),y=contam)

    p1 <- ggplot() + 
      geom_bar(data=data, aes(fill=columns, y=diffs, x=samps), stat="identity", position="fill") + 
      scale_fill_discrete(name="Preprocessing Steps",labels=labels,guide = guide_legend(order = 1)) +
      theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
      xlab("Samples") + ylab("Fractions of all reads") +
      geom_point(data=dffs1, aes(x=x,y=y,colour = "Recorded\nContaminant\nValues")) +
      scale_colour_manual(values = "black", name = "")

    p2 <- ggplot() + 
      geom_bar(data=data, aes(fill=columns, y=diffs, x=samps), stat="identity") + 
      scale_fill_discrete(name="Preprocessing Steps",labels=labels,guide = guide_legend(order = 1)) +
      theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
      xlab("Samples") + ylab("Read counts") +
      geom_point(data=dffs2, aes(x=x,y=y,colour = "Recorded\nContaminant\nValues")) +
      scale_colour_manual(values = "black", name = "")
    
    grid.arrange(p1,p2)
} else {
    p1 <- ggplot(data, aes(fill=columns, y=diffs, x=samps)) + 
      geom_bar(stat="identity", position="fill") + 
      scale_fill_discrete(name="Preprocessing Steps",labels=labels) +
      theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
      xlab("Samples") + ylab("Fractions of all reads")
  
    p2 <- ggplot(data, aes(fill=columns, y=diffs, x=samps)) + 
      geom_bar(stat="identity") + 
      scale_fill_discrete(name="Preprocessing Steps",labels=labels) +
      theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
      xlab("Samples") + ylab("Fractions of all reads")
    
    grid.arrange(p1,p2)
}
```


## **<u>MDS Plot</u>**

Multidimensional scaling (MDS) is a means of visualizing the level of similarity of individual cases of a dataset. MDS is used to translate information about the pairwise 'distances' among a set of n objects or individuals into a configuration of n points mapped onto a two-dimensional space.

```{r, echo=FALSE}
countdge = DGEList(counts_all)
countdge = calcNormFactors(countdge)
tmp <- as.data.frame(cpm(countdge))
tmp$Gene <- rownames(tmp)
tmp <- select(tmp, Gene, everything())
write.table(tmp, file = "normalized_counts.txt", quote = F, sep = "\t", row.names = F)
plotMDS(countdge, main="MDS Plot",cex=0.8)
```

