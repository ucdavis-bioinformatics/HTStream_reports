---
title: "Preproc mapping stats for Dickinson - Choroid Plexus"
output: html_notebook
---

```{r, echo=FALSE}
### SETTINGS ###
working_dir = "/share/biocore/joshi/projects/Dickinson_P_UCDVM/2019_choroid_plexus"
preproc_dir = "01-Cleaned"
mapping_dir = "02-STAR"
# none, first, second
strandedness = "none"
######################
```

```{r setup, echo=FALSE}
knitr::opts_knit$set(root.dir = working_dir)
```

```{r, echo=FALSE}

strandcol = matrix(1:3,ncol=1)
rownames(strandcol) = c("none","first","second")

library(knitr)
library(kableExtra)
library(jsonlite)
library(readr)
library(stringr)
library(edgeR)

process_step <- function(json_step,step_name,orig_input) {
    if (startsWith(step_name,"hts_Stats")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("Stats Input"=json_step$totalFragmentsInput, "Stats Output"=json_step$totalFragmentsOutput, "Stats Perc"=perc)
    } else if (startsWith(step_name,"hts_SeqScreener")) {
        if (json_step$record == 1) {
            total_hits = json_step$Single_end$SE_hits + json_step$Paired_end$PE_hits
            perc = sprintf("%.02f%%",100*total_hits/orig_input)
            retval = c("SeqScreener Input"=json_step$totalFragmentsInput, "SeqScreener Recorded Contaminants"=total_hits, "Recorded Contaminants perc"=perc)
        } else {
            perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
            retval = c("SeqScreener Input"=json_step$totalFragmentsInput, "SeqScreener Output"=json_step$totalFragmentsOutput, "SeqScreener Perc"=perc)
        }
    } else if (startsWith(step_name,"hts_SuperDeduper")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("SuperDeduper Input"=json_step$totalFragmentsInput, "SuperDeduper Output"=json_step$totalFragmentsOutput, "SuperDeduper Perc"=perc)
    } else if (startsWith(step_name,"hts_AdapterTrimmer")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("AdapterTrimmer Input"=json_step$totalFragmentsInput, "AdapterTrimmer Output"=json_step$totalFragmentsOutput, "AdapterTrimmer Perc"=perc)
    } else if (startsWith(step_name,"hts_QWindowTrim")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("QWindowTrim Input"=json_step$totalFragmentsInput, "QWindowTrim Output"=json_step$totalFragmentsOutput, "QWindowTrim Perc"=perc)
    } else if (startsWith(step_name,"hts_CutTrim")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("CutTrim Input"=json_step$totalFragmentsInput, "CutTrim Output"=json_step$totalFragmentsOutput, "CutTrim Perc"=perc)
    } else if (startsWith(step_name,"hts_Overlapper")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("Overlapper Input"=json_step$totalFragmentsInput, "Overlapper Output"=json_step$totalFragmentsOutput, "Overlapper Perc"=perc)
    } else if (startsWith(step_name,"hts_NTrimmer")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("NTrimmer Input"=json_step$totalFragmentsInput, "NTrimmer Output"=json_step$totalFragmentsOutput, "NTrimmer Perc"=perc)
    } else if (startsWith(step_name,"hts_PolyATTrim")) {
        perc = sprintf("%.02f%%",100*json_step$totalFragmentsOutput/orig_input)
        retval = c("PolyATTrim Input"=json_step$totalFragmentsInput, "PolyATTrim Output"=json_step$totalFragmentsOutput, "PolyATTrim Perc"=perc)
    }
  
    return(retval)
}

process_json <- function(sdir) { 
    json <- fromJSON(paste0(preproc_dir,"/",sdir,"/",sdir,".stats.log"))
    
    first_step = names(json)[1]
    orig_input = json[[first_step]]$totalFragmentsInput
    
    stats = unlist(lapply(names(json), function(x) process_step(json[[x]],x,orig_input)))
    
    logfinal = read_file(paste0(mapping_dir,"/",sdir,"/",sdir,".Log.final.out"))
    lfall = str_match_all(logfinal,"(?s)Uniquely mapped reads number \\|\\t(\\d+)\\n.+Uniquely mapped reads \\% \\|\\t(.+?\\%).+Number of reads mapped to multiple loci \\|\\t(\\d+)\\n.+\\% of reads mapped to multiple loci \\|\\t(.+?\\%)")
    
    lfm = c("Uniquely Mapped Reads"=lfall[[1]][,2], "Uniquely Mapped Perc"=lfall[[1]][,3], "Multi-Mapped Reads"=lfall[[1]][,4], "Multi-Mapped Perc"=lfall[[1]][,5])
    
    stats = c(stats,lfm)
    return(stats)
}

process_counts <- function(sid, colnum) {
  counts = read.table(paste0(mapping_dir,"/",sid,"/",sid,".ReadsPerGene.out.tab"),row.names = 1,skip = 4,sep='\t',stringsAsFactors = F)
  counts = counts[,colnum]
  return(counts)
}
```

```{r, echo=FALSE}
###################
sample_dirs = list.dirs(preproc_dir,full.names = F, recursive = F)
final_stats = t(sapply(sample_dirs, process_json))

counts_all = sapply(sample_dirs,process_counts,colnum=strandcol[strandedness,])
counts = read.table(paste0(mapping_dir,"/",sample_dirs[1],"/",sample_dirs[1],".ReadsPerGene.out.tab"),row.names = 1,skip = 4,sep='\t',stringsAsFactors = F)
rownames(counts_all) = rownames(counts)

write.table(counts_all,file="counts_all.out",sep='\t',quote=F,row.names=T)

rmg = as.matrix(colSums(counts_all), ncol=1)
mr = as.matrix(as.integer(final_stats[,1]), ncol=1)
perc_rmg = as.matrix(sprintf("%.02f%%", (rmg / mr) * 100), ncol=1)

fscol = colnames(final_stats)
final_stats = cbind(final_stats,rmg,perc_rmg)
colnames(final_stats) = c(fscol,"Reads Mapped to Genes","Perc Reads Mapped to Genes")

###################
```

## <u>**Preprocessing & Mapping stats**</u>
Preprocessing was done using the [HTStream](https://ibest.github.io/HTStream/) software. The table below shows the number of reads input and output at each step as well as the percentage of reads left (based on the initial input amount). Here are explantions of the various possible steps in your output (Note, your output will not contain every one of these steps):

* hts_AdapterTrimmer: Trims adapters which are sequenced when the fragment insert length is shorter than the read length.
* hts_CutTrim: Trims a fixed number of bases from the 5' and/or 3' end of each read.
* hts_Overlapper: Overlaps paired end reads to produce the original fragment, trims adapters, and can correct sequencing errors.
* hts_QWindowTrim: Uses a sliding window approach to remove the low quality ends of reads.
* hts_Stats: Generates an JSON formatted file containing a set of statistical measures about the input read data.
* hts_NTrimmer: Trims reads to the longest subsequence that contains no Ns.
* hts_PolyATTrim: Trims poly-A and poly-T sequences from the end of reads.
* hts_SeqScreener: A simple sequence screening tool which uses a kmer lookup approach to identify reads from an unwanted source. By default it will look for reads which are likely to have come from PhiX (commonly added to Illumina sequencing runs).
* hts_SuperDeduper: A reference free duplicate read removal tool.

The "Uniquely Mapped Reads", "Uniquely Mapped Perc", "Multi-Mapped Reads", and "Multi-Mapped Perc" columns are all taken from the log files of the aligner. Finally, the "Reads Mapped to Genes", and "Perc Reads Mapped to Genes" columns are calculated from the files of count data and original input numbers.

```{r, echo=FALSE}
numcol = dim(final_stats)[2]
step=6
for (i in seq(1,numcol,step)) {
  if (i+step-1 <= numcol) {
    endcol <- i+step-1
  } else {
    endcol <- numcol
  }
  
  print(kable(final_stats[,i:endcol]) %>% kable_styling(bootstrap_options = c("striped", "hover")))
}
```


## **<u>MDS Plot</u>**

Multidimensional scaling (MDS) is a means of visualizing the level of similarity of individual cases of a dataset. MDS is used to translate information about the pairwise 'distances' among a set of n objects or individuals into a configuration of n points mapped onto a two-dimensional space.

```{r, echo=FALSE}
countdge = DGEList(counts_all)
countdge = calcNormFactors(countdge)
plotMDS(countdge, main="MDS Plot")
```

